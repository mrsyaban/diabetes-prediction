{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"f3e2cd04bd4549bd805c97d378f4d934","deepnote_cell_type":"markdown"},"source":["# Praktikum IF3270 2023/2024\n","\n","Tujuan praktikum IF3270 Pembelajaran Mesin:\n","1.   Peserta memahami rangkaian proses analitik data menggunakan pendekatan pembelajaran mesin. \n","2.   Peserta memahami bahwa proses pengembangan model pembelajaran mesin juga ditentukan dari kualitas data, penanganan data, dan penentuan algoritma serta hyperparameter-nya; tidak cukup hanya dengan memastikan implementasi algoritma berjalan tanpa kesalahan.\n","3.   Peserta mampu menginterpretasikan hasil dari evaluasi model dalam proses analitik menggunakan pendekatan pembelajaran mesin.\n","\n","Praktikum dilaksanakan secara berkelompok. Setiap kelompok terdiri atas 2 mahasiswa. Perhatikan bahwa terdapat berkas yang harus dikumpulkan saat keberjalanan praktikum untuk bagian A (25 April 2024, pukul 12.00 WIB) dan berkas yang dikumpulkan setelah waktu praktikum selesai untuk bagian B (25 April 2024, pukul 21.00 WIB)."]},{"cell_type":"markdown","metadata":{"cell_id":"b8e6e048bb054992aa243802c05d4b28","deepnote_cell_type":"markdown"},"source":["Disediakan data yang sudah dibagi menjadi data latih (`df_train`), data validasi (`df_val`), dan data uji (`df_test`).\n","\n","**Bagian 1**: (batas waktu: 25 April 2024, 12.00 WIB)\n","\n","1. Buatlah _baseline_ dengan menggunakan model _logistic regression_.\n","2. Lakukan analisis data terkait hal berikut:\n","    - _duplicate value_,\n","    - _missing value_,\n","    - _outlier_,\n","    - _balance of data_.\n","3. Jelaskan rencana penanganan yang ada pada poin 2.\n","4. Jelaskan teknik _encoding_ yang digunakan terhadap data yang disediakan apabila dilakukan, disertai dengan alasan.\n","5. Buatlah desain eksperimen dengan menentukan hal berikut:\n","    - tujuan eksperimen,\n","    - variabel dependen dan independen,\n","    - strategi eksperimen,\n","    - skema validasi.\n","    \n","**Bagian 2**: (batas waktu: 25 April 2024, 21.00 WIB)\n","\n","6. Implementasikan strategi eksperimen dan skema validasi yang telah ditentukan pada poin 5.\n","7. Berdasarkan hasil prediksi yang dihasilkan, buatlah kesimpulan analisis **hasil diabetes**.\n","\n","---\n","Catatan:\n","- Jika terdapat perubahan jawaban pada poin 1—5 (contoh: perbedaan penanganan _outlier_), jelaskan pada laporan mengenai jawaban sebelum, jawaban sesudah, dan alasan pengubahan jawaban.\n","- Eksperimen dapat berupa penggantian model klasifikasi, pengaturan hyperparameter, model stacking, grid search, oversampling, undersampling, dan lain sebagainya. Semakin variatif eksperimen yang dilakukan, semakin baik."]},{"cell_type":"markdown","metadata":{"cell_id":"b1891f217d7b437191c9e752b1df5b30","deepnote_cell_type":"markdown"},"source":["## Dataset\n","`diabetes.csv` merupakan dataset yang telah dimodifikasi dari [Diabetes Health Indicators Dataset](https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset/) sebagai kumpulan indikator individu yang diperoleh dari survei untuk kasus diabetes. Dataset ini berguna untuk melakukan prediksi diabetes sehingga suatu individu dapat diketahui memiliki risiko tinggi diabetes atau tidak. Hal ini diperoleh dari fitur-fitur yang dapat dianalisis lebih lanjut sebelum mencapai kesimpulan.\n","\n","Berikut adalah deskripsi singkat setiap kolom:\n","\n","1. **HighBP**: Memiliki tekanan darah tinggi (BP: Blood Pressure) atau tidak\n","2. **HighChol**: Kolesterol tinggi atau tidak\n","3. **BMI**: Besaran Body Mass Index\n","4. **Smoker**: Perokok atau bukan perokok\n","5. **Stroke**: Pernah mengalami struk atau tidak\n","6. **HeartDiseaseorAttack**: Memiliki riwayat penyakit antara jantung koroner dan serangan jantung atau tidak sama sekali\n","7. **PhysActivity**: Aktif secara fisik dalam 30 hari terakhir atau tidak\n","8. **Fruits**: Mengonsumsi buah setiap hari atau tidak \n","9. **Veggies**: Mengonsumsi sayur setiap hari atau tidak\n","10. **HvyAlcoholConsump**: Peminum berat alkohol atau bukan \n","11. **AnyHealthcare**: Memiliki perlindungan kesehatan atau tidak, contohnya memiliki asuransi kesehatan\n","12. **GenHtlth**: Evaluasi mandiri terhadap kesehatan, skala 1-5 (1: Sangat baik, 2: Cukup Baik, 3: Baik, 4: Biasa saja, 5: Buruk)\n","13. **MentHlth**: Jumlah hari keadaan mental buruk dalam 30 hari terakhir (skala 0-30 hari)  \n","14. **PhysHlth**: Jumlah hari keadaan fisik buruk dalam 30 hari terakhir (skala 0-30 hari)\n","15. **DiffWalk**: Memiliki kesulitan berjalan atau menaiki tangga\n","16. **Sex**: (M) Male atau (F) Female\n","17. **Age**: 13 kategori umur (1: 18-24 tahun, 9: 60-64 tahun, 13: 80 tahun ke atas)\n","18. **Education**: Level edukasi skala 1-6 (1: Tidak pernah sekolah atau hanya TK, 2: SD, dst)\n","19. **Income**: Skala pendapatan 1-8\n","20. **Diabetes**: Apakah mengalami diabetes atau tidak (Kolom target)"]},{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"707da77e189b4d16839ece1b85a8fb7c","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":206,"execution_start":1714046202371,"source_hash":"531eb69f"},"outputs":[],"source":["# Import library di sini\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import keras\n","import tensorflow as tf\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from scikeras.wrappers import KerasRegressor\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n","from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n","from sklearn.preprocessing import MinMaxScaler\n","from imblearn.under_sampling import RandomUnderSampler\n","from imblearn.over_sampling import RandomOverSampler, SMOTE"]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"943a698cc7264b499bdee1214d62db20","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":421,"execution_start":1714039921276,"source_hash":"c76f6cab"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 50736 entries, 0 to 50735\n","Data columns (total 20 columns):\n"," #   Column                Non-Null Count  Dtype  \n","---  ------                --------------  -----  \n"," 0   HighBP                50736 non-null  float64\n"," 1   HighChol              50736 non-null  float64\n"," 2   BMI                   50736 non-null  float64\n"," 3   Smoker                50736 non-null  float64\n"," 4   Stroke                50736 non-null  float64\n"," 5   HeartDiseaseorAttack  50736 non-null  float64\n"," 6   PhysActivity          50736 non-null  float64\n"," 7   Fruits                50736 non-null  float64\n"," 8   Veggies               50736 non-null  float64\n"," 9   HvyAlcoholConsump     50736 non-null  float64\n"," 10  AnyHealthcare         50736 non-null  float64\n"," 11  GenHlth               50736 non-null  float64\n"," 12  MentHlth              50736 non-null  float64\n"," 13  PhysHlth              50736 non-null  float64\n"," 14  DiffWalk              50736 non-null  float64\n"," 15  Sex                   50736 non-null  int64  \n"," 16  Age                   50736 non-null  float64\n"," 17  Education             50736 non-null  float64\n"," 18  Income                50736 non-null  float64\n"," 19  Diabetes              50736 non-null  int64  \n","dtypes: float64(18), int64(2)\n","memory usage: 7.7 MB\n"]}],"source":["data = pd.read_csv(\"diabetes.csv\")\n","\n","# Encode Sex column's record with Label encoding\n","data[\"Sex\"].replace({\"M\":1,\"F\":0}, inplace=True)\n","data[\"Diabetes\"].replace({True:1,False:0}, inplace=True)\n","data.info()"]},{"cell_type":"code","execution_count":3,"metadata":{"cell_id":"8785116f138c49a6a962b7e4f1af48fa","deepnote_cell_type":"code","deepnote_table_loading":false,"deepnote_table_state":{"filters":[],"pageIndex":1,"pageSize":10,"sortBy":[]},"deepnote_to_be_reexecuted":false,"execution_millis":368,"execution_start":1714035894985,"source_hash":null},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>HighBP</th>\n","      <th>HighChol</th>\n","      <th>BMI</th>\n","      <th>Smoker</th>\n","      <th>Stroke</th>\n","      <th>HeartDiseaseorAttack</th>\n","      <th>PhysActivity</th>\n","      <th>Fruits</th>\n","      <th>Veggies</th>\n","      <th>HvyAlcoholConsump</th>\n","      <th>AnyHealthcare</th>\n","      <th>GenHlth</th>\n","      <th>MentHlth</th>\n","      <th>PhysHlth</th>\n","      <th>DiffWalk</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>Education</th>\n","      <th>Income</th>\n","      <th>Diabetes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>31261</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>27.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>7.0</td>\n","      <td>6.0</td>\n","      <td>8.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>29945</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>27.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>7.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>36013</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>29.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>303</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>37.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>10.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49282</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>22.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>8.0</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5167</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>29.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>11.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>42843</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>26.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34259</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14692</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>25.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>20.0</td>\n","      <td>20.0</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>9.0</td>\n","      <td>6.0</td>\n","      <td>3.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>50571</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>8.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 20 columns</p>\n","</div>"],"text/plain":["       HighBP  HighChol   BMI  Smoker  Stroke  HeartDiseaseorAttack  \\\n","31261     0.0       1.0  27.0     0.0     0.0                   0.0   \n","29945     0.0       0.0  27.0     1.0     0.0                   0.0   \n","36013     0.0       0.0  29.0     0.0     0.0                   0.0   \n","303       1.0       0.0  37.0     0.0     0.0                   0.0   \n","49282     0.0       1.0  22.0     1.0     0.0                   0.0   \n","...       ...       ...   ...     ...     ...                   ...   \n","5167      1.0       0.0  29.0     1.0     0.0                   1.0   \n","42843     0.0       0.0  26.0     0.0     0.0                   0.0   \n","34259     0.0       0.0  51.0     1.0     0.0                   0.0   \n","14692     1.0       0.0  25.0     1.0     0.0                   0.0   \n","50571     0.0       0.0  22.0     0.0     0.0                   0.0   \n","\n","       PhysActivity  Fruits  Veggies  HvyAlcoholConsump  AnyHealthcare  \\\n","31261           1.0     1.0      1.0                0.0            1.0   \n","29945           1.0     1.0      1.0                0.0            1.0   \n","36013           0.0     0.0      1.0                0.0            1.0   \n","303             1.0     0.0      1.0                0.0            1.0   \n","49282           0.0     0.0      1.0                0.0            1.0   \n","...             ...     ...      ...                ...            ...   \n","5167            0.0     1.0      1.0                0.0            1.0   \n","42843           0.0     0.0      0.0                0.0            0.0   \n","34259           1.0     1.0      1.0                0.0            0.0   \n","14692           1.0     1.0      1.0                0.0            1.0   \n","50571           1.0     1.0      1.0                0.0            1.0   \n","\n","       GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  Income  \\\n","31261      3.0       0.0       0.0       0.0    0   7.0        6.0     8.0   \n","29945      2.0       0.0       1.0       0.0    1   5.0        5.0     7.0   \n","36013      1.0       0.0       0.0       0.0    1   2.0        5.0     6.0   \n","303        1.0       0.0       0.0       0.0    0  10.0        5.0     6.0   \n","49282      3.0       0.0       0.0       0.0    1   8.0        6.0     6.0   \n","...        ...       ...       ...       ...  ...   ...        ...     ...   \n","5167       2.0       0.0       0.0       0.0    1  11.0        4.0     6.0   \n","42843      2.0       4.0       0.0       0.0    1   3.0        5.0     6.0   \n","34259      3.0       3.0       2.0       0.0    1   2.0        3.0     4.0   \n","14692      3.0      20.0      20.0       1.0    1   9.0        6.0     3.0   \n","50571      2.0       0.0       0.0       0.0    1   4.0        4.0     8.0   \n","\n","       Diabetes  \n","31261         0  \n","29945         0  \n","36013         0  \n","303           0  \n","49282         0  \n","...         ...  \n","5167          0  \n","42843         0  \n","34259         1  \n","14692         1  \n","50571         0  \n","\n","[100 rows x 20 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["data.sample(100)"]},{"cell_type":"code","execution_count":4,"metadata":{"cell_id":"2dee8e15f8dd49b3913ab68ae9ac14de","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":74,"execution_start":1714039924549,"source_hash":"ae698fb0"},"outputs":[],"source":["X = data.drop(columns=\"Diabetes\")\n","y = data[\"Diabetes\"].copy()\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=123)\n","\n","# Gunakan data validasi untuk bereksperimen dengan model\n","# Gunakan data test untuk mengevaluasi model hanya di akhir eksperimen\n","df_train = pd.concat([X_train, y_train], axis=1)\n","df_val = pd.concat([X_val, y_val], axis=1)\n","df_test = pd.concat([X_test, y_test], axis=1)"]},{"cell_type":"markdown","metadata":{"cell_id":"740beebff9ca4ddc98155949088b195d","deepnote_cell_type":"markdown"},"source":["_Deliverable_ yang akan dihasilkan adalah sebagai berikut:\n","1. berkas _notebook_ dengan format nama `PraktikumIF3270_M1_NIM1_NIM2.ipynb` untuk Bagian 1;\n","2. berkas _notebook_ dengan format nama `PraktikumIF3270_M2_NIM1_NIM2.ipynb` untuk Bagian 1 + Bagian 2; serta\n","3. berkas laporan dengan format nama `PraktikumIF3270_NIM1_NIM2.pdf` yang mencakup hal berikut:\n","    - hasil analisis data,\n","    - penanganan dari hasil analisis data,\n","    - justifikasi teknik-teknik yang dipilih,\n","    - perubahan yang dilakukan pada jawaban poin 1—5 jika ada,\n","    - desain eksperimen,\n","    - hasil eksperimen,\n","    - analisis dari hasil eksperimen,\n","    - kesimpulan,\n","    - pembagian tugas/kerja per anggota kelompok\n","\n","Batas waktu pengumpulan:\n","- _Deliverable_ poin 1: Senin, 25 April 2023, pukul 12.00 WIB\n","- _Deliverable_ poin 2: Senin, 25 April 2023, pukul 21.00 WIB\n","- _Deliverable_ poin 3: Senin, 25 April 2023, pukul 21.00 WIB"]},{"cell_type":"markdown","metadata":{"cell_id":"a7679070e986452e800267f86e5bfdb9","deepnote_cell_type":"markdown"},"source":["## Bagian 1"]},{"cell_type":"markdown","metadata":{"cell_id":"9d08205929ff461b95ab3ad6bc15b388","deepnote_cell_type":"markdown"},"source":["#### 1. Buatlah _baseline_ dengan menggunakan model _logistic regression_."]},{"cell_type":"code","execution_count":5,"metadata":{"cell_id":"2a9283ad4f184d5abdd3b2fab0d618f1","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":7603,"execution_start":1714039928011,"source_hash":"16de4f24"},"outputs":[{"name":"stdout","output_type":"stream","text":["F1 Score: 0.23902087832973362\n","Confusion Matrix:\n","[[6895  925]\n"," [ 132  166]]\n"]}],"source":["baseline_model = LogisticRegression(max_iter=1000, random_state=42)\n","baseline_model.fit(X_train, y_train)\n","\n","y_pred = baseline_model.predict(X_val)\n","print(f\"F1 Score: {f1_score(y_pred, y_val)}\")\n","print(f\"Confusion Matrix:\\n{confusion_matrix(y_pred, y_val)}\")"]},{"cell_type":"markdown","metadata":{"cell_id":"013c6cdbec6a42a1893d201936dca7c6","deepnote_cell_type":"markdown"},"source":["#### 2. Lakukan analisis data terkait hal berikut:\n","####    - _duplicate value_,\n"]},{"cell_type":"code","execution_count":6,"metadata":{"cell_id":"b5dec67a26cf4d04baf364fe5923931c","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":115,"execution_start":1714039983516,"source_hash":"8d21a769"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of duplicate value:\n","  2329\n"]}],"source":["\n","duplicateValue = data[data.duplicated()]\n","print(\"Number of duplicate value:\\n \", len(duplicateValue))"]},{"cell_type":"markdown","metadata":{"cell_id":"0a87a5ce162f4d948abe93d53c4d4ecb","deepnote_cell_type":"markdown"},"source":["####    - _missing value_,"]},{"cell_type":"code","execution_count":7,"metadata":{"cell_id":"75808473542a4b91a0e0bb069390d46d","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":104,"execution_start":1714040012490,"source_hash":"810a4841"},"outputs":[{"name":"stdout","output_type":"stream","text":["Missing values in each column:\n","HighBP                  0\n","HighChol                0\n","BMI                     0\n","Smoker                  0\n","Stroke                  0\n","HeartDiseaseorAttack    0\n","PhysActivity            0\n","Fruits                  0\n","Veggies                 0\n","HvyAlcoholConsump       0\n","AnyHealthcare           0\n","GenHlth                 0\n","MentHlth                0\n","PhysHlth                0\n","DiffWalk                0\n","Sex                     0\n","Age                     0\n","Education               0\n","Income                  0\n","Diabetes                0\n","dtype: int64\n"]}],"source":["# missing Value\n","missingValues = data.isnull().sum()\n","print(\"Missing values in each column:\")\n","print(missingValues)"]},{"cell_type":"markdown","metadata":{"cell_id":"0b9519dbb0994e3984c01955f86cfe25","deepnote_cell_type":"markdown"},"source":["####    - _outlier_,"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"1c966d6784194994b58ec041c0c7fe44","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":7291,"execution_start":1714040017027,"source_hash":"d092fcf5"},"outputs":[],"source":["# outliers\n","for col in data.columns:\n","    if data[col].dtype == \"float64\" or data[col].dtype == \"int64\":\n","        q1 = data[col].quantile(0.25)\n","        q3 = data[col].quantile(0.75)\n","        iqr = q3 - q1\n","        lowerBound = q1 - (1.5 * iqr)\n","        upperBound = q3 + (1.5 * iqr)\n","\n","        insideRange = len(data[(data[col] >= lowerBound) & (data[col] <= upperBound)])\n","        outsideRange = len(data[(data[col] < lowerBound) | (data[col] > upperBound)])\n","\n","        print(f\"{col} have {outsideRange} outlier data\")\n","\n","# outliers visualization\n","for col in data.columns:\n","    if data[col].dtype == \"int64\" or data[col].dtype == \"float64\":\n","        plt.figure(figsize=(10, 5))\n","        sns.boxplot(x=data[col], color='skyblue', linewidth=2.5, fliersize=5, whis=1.5)\n","        plt.title(col, fontsize=16)\n","        plt.xlabel('values', fontsize=14)\n","        plt.ylabel(col, fontsize=14)\n","        plt.xticks(fontsize=12)\n","        plt.yticks(fontsize=12)\n","        plt.show()"]},{"cell_type":"markdown","metadata":{"cell_id":"f55b8682b2f448c48196f76743cec3ad","deepnote_cell_type":"markdown"},"source":["####   - _balance of data_."]},{"cell_type":"code","execution_count":9,"metadata":{"cell_id":"37724aa23d8047c693ea04eb1954b359","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":121,"execution_start":1714040033491,"source_hash":"77b3fa25"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Values  Count\n","0       0  43790\n","1       1   6946\n"]}],"source":["# balance of data\n","uniqueValues, uniqueCount = np.unique(y, return_counts=True)\n","print(pd.DataFrame({\"Values\": uniqueValues, \"Count\": uniqueCount}))"]},{"cell_type":"markdown","metadata":{"cell_id":"e713e56ecb68489ab113941f05ce346e","deepnote_cell_type":"markdown"},"source":["#### 3. Jelaskan rencana penanganan yang ada pada poin 2."]},{"cell_type":"markdown","metadata":{"cell_id":"3ebbd7438a1b4172b9317aa7b7e14f3b","deepnote_cell_type":"markdown"},"source":["1. Duplicate Value\n","duplicate value akan ditangani dengan mempertahankan salah satu data dan menghapus yang lainnya dengan menggunakan fungsi `drop_duplicates()`\n","\n","2. Missing Value\n","dikarenakan tidak ada missing value sama sekali pada dataset sehingga tidak perlu ada penanganan yang dilakukan.\n","\n","3. Outlier\n","karena dataset berukuran cukup besar dan jumlah outlier cukup kecil dibandingkan dengan jumlah keseluruhan data maka untuk menangani outlier dilakukan dengan cara trimming atau menghilangkan data yang mengandung outlier\n","\n","4. Balance of Data\n","karena terdapat 43790 nilai \"False\" dan 6946 nilai \"True\", maka akan dilakukan teknik Oversampling dan Undersampling. Pemilihan teknik yang digunakan akan didasarkan pada matriks evaluasi F1-Score, teknik dengan nilai F1-Score yang lebih tinggi akan digunakan sebagai teknik untuk menangani ketidak seimbangan data."]},{"cell_type":"markdown","metadata":{"cell_id":"eead45338a4f4314bcefa7451127146a","deepnote_cell_type":"markdown"},"source":["\n","#### 4. Jelaskan teknik _encoding_ yang digunakan terhadap data yang disediakan apabila dilakukan, disertai dengan alasan."]},{"cell_type":"markdown","metadata":{"cell_id":"4c7f2bd138c941878fb2732f9aab6d82","deepnote_cell_type":"markdown"},"source":["Kami telah mencetak contoh _record_ yang tersimpan dalam data menggunakan perintah _data.head(5)_ dan juga informasi terkait tiap atribut menggunakan perintah _data.info()_. Hasilnya menunjukkan bahwa hanya akan dilakukan dua kali proses encoding pada kolom **Sex** (nilainya berupa objek \"M\" dan \"F\") dan kolom target **Diabetes** (nilainya berupa bool _true_ dan _false_). Oleh karena itu, kami menggunakan teknik encoding yang disebut sebagai _label encoding_. Metode tersebut akan memetakan tiap nilai kategorik menjadi nilai numerik yang unik mulai dari 0, 1, 2, 3, dst.\n","\n","Terdapat kelebihan dan kekurangan di dalam penggunaan teknik _label encoding_. Kelebihannya adalah teknik tersebut sangat mudah untuk digunakan. Akan tetapi, pada kasus tertentu, misalkan apabila sebuah kolom memiliki nilai lebih dari 3 kategori, maka akan terbentuk semacam nilai berurutan. Hal itu dapat menjadi sisi kekurangan dari penggunaan _label encoding_, karena dapat memungkinkan sebuah model untuk memberikan bobot yang tidak diinginkan pada nilai numerik yang berbeda. Namun, karena kolom **Sex** dan **Diabetes** hanya memiliki 2 nilai kategori, maka kekurangan dari _label encoding_ tidak akan berdampak pada model yang dibuat, karena nilai kardinalitasnya rendah."]},{"cell_type":"markdown","metadata":{"cell_id":"5dc4ea5c5eb547f4a4a9aaa482d579b1","deepnote_cell_type":"markdown"},"source":["#### 5. Buatlah desain eksperimen dengan menentukan hal berikut:\n","####    - tujuan eksperimen\n","####    - variabel dependen dan independen\n","####    - strategi eksperimen\n","####    - skema validasi"]},{"cell_type":"markdown","metadata":{"cell_id":"a33446fa09c1479fa262d35dbd1a88e9","deepnote_cell_type":"markdown"},"source":["**Tujuan Eksperimen** : Membuat sebuah model yang dapat mengklasifikasikan apakah seseorang dengan kondisi kesehatan tertentu mulai dari nilai tekanan darah, kolesterol, _Body Mass Index_ (BMI), perokok, pernah menderita struk, riwayat penyakit jantung koroner dan serangan jantung, aktivitas fisik, konsumsi buah, mengkonsumsi sayur, peminum alkohol, pemilik perlindungan kesehatan, evaluasi mandiri kesehatan, jumlah hari dengan mental dan keadaan fisik yang buruk, kesulitan berjalan, jenis kelamin,  umur, taraf pendidikan, dan pemasukan beresiko untuk terkena penyakit diabetes atau tidak. \n","\n","**Variabel Dependen** :\n"," - Diabetes (biner: 0 untuk Tidak Diabetes, 1 untuk Diabetes)\n","\n","**Variabel Independen** : \n","- HighBP: Tekanan darah tinggi (biner: 0 untuk Tidak, 1 untuk Ya)\n","- HighChol: Kolesterol tinggi (biner: 0 untuk Tidak, 1 untuk Ya)\n","- BMI: Indeks Massa Tubuh (kontinu)\n","- Smoker: Perokok (biner: 0 untuk Tidak, 1 untuk Ya)\n","- Stroke: Riwayat stroke (biner: 0 untuk Tidak, 1 untuk Ya)\n","- HeartDiseaseorAttack: Penyakit jantung atau serangan jantung (biner: 0 untuk Tidak, 1 untuk Ya)\n","- PhysActivity: Aktivitas fisik (biner: 0 untuk Tidak, 1 untuk Ya)\n","- Fruits: Konsumsi buah-buahan (kontinu)\n","- Veggies: Konsumsi sayuran (kontinu)\n","- HvyAlcoholConsump: Konsumsi alkohol berat (biner: 0 untuk Tidak, 1 untuk Ya)\n","- AnyHealthcare: Pelayanan kesehatan yang tersedia (biner: 0 untuk Tidak, 1 untuk Ya)\n","- GenHlth: Kesehatan umum (kontinu)\n","- MentHlth: Kesehatan mental (kontinu)\n","- PhysHlth: Kesehatan fisik (kontinu)\n","- DiffWalk: Kesulitan berjalan (kontinu)\n","- Sex: Jenis kelamin (biner: 0 untuk Female, 1 untuk Male)\n","- Age: Usia (kontinu)\n","- Education: Tingkat pendidikan (kontinu)\n","- Income: Pendapatan (kontinu)\n","\n","**Strategi Eksperimen**:\n","1. Pertama: Kami akan melakukan _data preprocessing_ (sesuai dengan apa yang termuat pada poin di atasnya). \n","2. Kedua: Kami juga melakukan proses lain seperti penggunaan data scaling menggunakan _min-max scaler_ atau semacamnya, serta telah dilakukan pula proses _label encoding_ untuk mengubah nilai dari suatu kolom yang formatnya tidak sesuai menjadi berformat int64 dengan nilai yang unik.\n","3. Ketiga : Kami akan membangun beberapa model yang tentunya dapat digunakan sebagai kakas _binary classification_ seperti: \n","    - Logistic regression\n","    - Support vector machines\n","    - Naive bayes\n","    - Neareset neighbor\n","    - Decision trees\n","    - Neural networks\n","4. Keempat : Kami akan memvalidasi model yang telah dibuat dengan skema validasi pada poin di bawah ini.\n","\n","**Strategi Validasi**:\n","Kami akan menggunakan skema validasi K-Fold untuk membagi _data training_ menjadi beberapa bagian. Kemudian akan digunakan matriks evaluasi F1-Score, serta model dengan nilai F1-Score tertinggi akan dipilih sebagai model terbaik."]},{"cell_type":"markdown","metadata":{"cell_id":"9d1868e674bc49baa90a0a8968add7ad","deepnote_cell_type":"markdown"},"source":["## Bagian 2"]},{"cell_type":"code","execution_count":10,"metadata":{"cell_id":"ddb1fca2107b4528b7c0ab3e6c4e75df","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":233,"execution_start":1714040477476,"source_hash":"93314c50"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>HighBP</th>\n","      <th>HighChol</th>\n","      <th>BMI</th>\n","      <th>Smoker</th>\n","      <th>Stroke</th>\n","      <th>HeartDiseaseorAttack</th>\n","      <th>PhysActivity</th>\n","      <th>Fruits</th>\n","      <th>Veggies</th>\n","      <th>HvyAlcoholConsump</th>\n","      <th>AnyHealthcare</th>\n","      <th>GenHlth</th>\n","      <th>MentHlth</th>\n","      <th>PhysHlth</th>\n","      <th>DiffWalk</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>Education</th>\n","      <th>Income</th>\n","      <th>Diabetes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>24.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>9.0</td>\n","      <td>6.0</td>\n","      <td>8.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>24.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>13.0</td>\n","      <td>6.0</td>\n","      <td>8.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>29.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>20.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>12.0</td>\n","      <td>6.0</td>\n","      <td>8.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>28.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>30.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>7.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>33.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>30.0</td>\n","      <td>15.0</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","      <td>11.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   HighBP  HighChol   BMI  Smoker  Stroke  HeartDiseaseorAttack  PhysActivity  \\\n","0     0.0       1.0  24.0     0.0     0.0                   0.0           1.0   \n","1     0.0       0.0  24.0     1.0     0.0                   0.0           1.0   \n","2     1.0       0.0  29.0     0.0     1.0                   0.0           1.0   \n","3     0.0       0.0  28.0     1.0     0.0                   0.0           1.0   \n","4     0.0       0.0  33.0     1.0     0.0                   1.0           1.0   \n","\n","   Fruits  Veggies  HvyAlcoholConsump  AnyHealthcare  GenHlth  MentHlth  \\\n","0     1.0      1.0                0.0            1.0      1.0       0.0   \n","1     1.0      1.0                0.0            1.0      2.0       0.0   \n","2     1.0      1.0                0.0            1.0      2.0      20.0   \n","3     1.0      1.0                0.0            1.0      2.0      30.0   \n","4     1.0      1.0                0.0            1.0      5.0      30.0   \n","\n","   PhysHlth  DiffWalk  Sex   Age  Education  Income  Diabetes  \n","0       0.0       0.0    0   9.0        6.0     8.0         0  \n","1       0.0       1.0    1  13.0        6.0     8.0         0  \n","2       5.0       0.0    0  12.0        6.0     8.0         0  \n","3       0.0       0.0    1   1.0        5.0     7.0         0  \n","4      15.0       1.0    0  11.0        4.0     3.0         0  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df = data.copy()\n","df.head(5)"]},{"cell_type":"markdown","metadata":{"cell_id":"6b9b0526495648ef84a7002b2fffe5a1","deepnote_cell_type":"markdown"},"source":["### Data Preprocessing"]},{"cell_type":"markdown","metadata":{},"source":["#### Data Scaling"]},{"cell_type":"code","execution_count":33,"metadata":{"cell_id":"9d9d695fd8ef4a63b7c83c06537c2f38","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":376,"execution_start":1714040479473,"source_hash":"b4d92783"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>HighBP</th>\n","      <th>HighChol</th>\n","      <th>BMI</th>\n","      <th>Smoker</th>\n","      <th>Stroke</th>\n","      <th>HeartDiseaseorAttack</th>\n","      <th>PhysActivity</th>\n","      <th>Fruits</th>\n","      <th>Veggies</th>\n","      <th>HvyAlcoholConsump</th>\n","      <th>AnyHealthcare</th>\n","      <th>GenHlth</th>\n","      <th>MentHlth</th>\n","      <th>PhysHlth</th>\n","      <th>DiffWalk</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>Education</th>\n","      <th>Income</th>\n","      <th>Diabetes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.354839</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.666667</td>\n","      <td>1.0</td>\n","      <td>1.000000</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.354839</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.25</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.000000</td>\n","      <td>1.0</td>\n","      <td>1.000000</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.516129</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.25</td>\n","      <td>0.666667</td>\n","      <td>0.166667</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.916667</td>\n","      <td>1.0</td>\n","      <td>1.000000</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.483871</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.25</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>0.8</td>\n","      <td>0.857143</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.645161</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.00</td>\n","      <td>1.000000</td>\n","      <td>0.500000</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.833333</td>\n","      <td>0.6</td>\n","      <td>0.285714</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   HighBP  HighChol       BMI  Smoker  Stroke  HeartDiseaseorAttack  \\\n","0     0.0       1.0  0.354839     0.0     0.0                   0.0   \n","1     0.0       0.0  0.354839     1.0     0.0                   0.0   \n","2     1.0       0.0  0.516129     0.0     1.0                   0.0   \n","3     0.0       0.0  0.483871     1.0     0.0                   0.0   \n","4     0.0       0.0  0.645161     1.0     0.0                   1.0   \n","\n","   PhysActivity  Fruits  Veggies  HvyAlcoholConsump  AnyHealthcare  GenHlth  \\\n","0           1.0     1.0      1.0                0.0            1.0     0.00   \n","1           1.0     1.0      1.0                0.0            1.0     0.25   \n","2           1.0     1.0      1.0                0.0            1.0     0.25   \n","3           1.0     1.0      1.0                0.0            1.0     0.25   \n","4           1.0     1.0      1.0                0.0            1.0     1.00   \n","\n","   MentHlth  PhysHlth  DiffWalk  Sex       Age  Education    Income  Diabetes  \n","0  0.000000  0.000000       0.0  0.0  0.666667        1.0  1.000000       0.0  \n","1  0.000000  0.000000       1.0  1.0  1.000000        1.0  1.000000       0.0  \n","2  0.666667  0.166667       0.0  0.0  0.916667        1.0  1.000000       0.0  \n","3  1.000000  0.000000       0.0  1.0  0.000000        0.8  0.857143       0.0  \n","4  1.000000  0.500000       1.0  0.0  0.833333        0.6  0.285714       0.0  "]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["# Proses scaling menggunakan MinMaxScaler\n","scaler = MinMaxScaler()\n","for col in df.columns:\n","    if df[col].dtype == \"int64\" or df[col].dtype == \"float64\":\n","        scaled_data = scaler.fit_transform(df[col].values.reshape(-1, 1))\n","        df[col] = scaled_data.flatten()\n","\n","df.head(5)"]},{"cell_type":"markdown","metadata":{},"source":["#### Drop duplicate values"]},{"cell_type":"code","execution_count":12,"metadata":{"cell_id":"97193c9be3eb4e8e98f6d8ad02239fe5","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"execution_millis":222,"execution_start":1714040482462,"source_hash":"5395f9c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["==================================================\n","Before drop duplicate values: (50736, 20)\n","After drop duplicate values: (48407, 20)\n","==================================================\n"]}],"source":["# Handling duplicate values\n","print(f\"{50*'='}\")\n","print(f\"Before drop duplicate values: {df.shape}\")\n","\n","df = df.drop_duplicates()\n","\n","print(f\"After drop duplicate values: {df.shape}\")\n","print(f\"{50*'='}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Drop Outlier Values"]},{"cell_type":"code","execution_count":13,"metadata":{"cell_id":"4709ef9004cb425a932ba8eee4941770","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":78,"execution_start":1714040484820,"source_hash":"657710d"},"outputs":[{"name":"stdout","output_type":"stream","text":["==================================================\n","Before trim outlier values: (48407, 20)\n","After trim outlier values: (47254, 20)\n","==================================================\n"]}],"source":["# Handling outlier values (hanya dilakukan pada kolom BMI, didasarkan pada domain knowledge)\n","print(f\"{50*'='}\")\n","print(f\"Before trim outlier values: {df.shape}\")\n","\n","q1 = df[\"BMI\"].quantile(0.25)\n","q3 = df[\"BMI\"].quantile(0.75)\n","iqr = q3 - q1\n","lower_bound = q1 - (1.5 * iqr)\n","upper_bound = q3 + (1.5 * iqr)\n","\n","df = df[(df[\"BMI\"] >= lower_bound) & (df[\"BMI\"] <= upper_bound)]\n","\n","print(f\"After trim outlier values: {df.shape}\")\n","print(f\"{50*'='}\")"]},{"cell_type":"code","execution_count":14,"metadata":{"cell_id":"6e3eb44c2a38408193f4dca87b080c6a","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":291,"execution_start":1714040487859,"source_hash":"f6df5482"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>HighBP</th>\n","      <th>HighChol</th>\n","      <th>BMI</th>\n","      <th>Smoker</th>\n","      <th>Stroke</th>\n","      <th>HeartDiseaseorAttack</th>\n","      <th>PhysActivity</th>\n","      <th>Fruits</th>\n","      <th>Veggies</th>\n","      <th>HvyAlcoholConsump</th>\n","      <th>AnyHealthcare</th>\n","      <th>GenHlth</th>\n","      <th>MentHlth</th>\n","      <th>PhysHlth</th>\n","      <th>DiffWalk</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>Education</th>\n","      <th>Income</th>\n","      <th>Diabetes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>8658</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.200000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.25</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.416667</td>\n","      <td>0.8</td>\n","      <td>0.714286</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>42382</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.294118</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.75</td>\n","      <td>1.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.500000</td>\n","      <td>0.4</td>\n","      <td>0.428571</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>11612</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.152941</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.00</td>\n","      <td>0.333333</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>0.8</td>\n","      <td>1.000000</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>17935</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.117647</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.25</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.250000</td>\n","      <td>0.8</td>\n","      <td>0.571429</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2651</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.211765</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.333333</td>\n","      <td>1.0</td>\n","      <td>1.000000</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       HighBP  HighChol       BMI  Smoker  Stroke  HeartDiseaseorAttack  \\\n","8658      1.0       0.0  0.200000     0.0     0.0                   0.0   \n","42382     0.0       0.0  0.294118     1.0     0.0                   0.0   \n","11612     1.0       0.0  0.152941     0.0     0.0                   0.0   \n","17935     0.0       0.0  0.117647     0.0     0.0                   0.0   \n","2651      0.0       0.0  0.211765     1.0     0.0                   0.0   \n","\n","       PhysActivity  Fruits  Veggies  HvyAlcoholConsump  AnyHealthcare  \\\n","8658            1.0     1.0      1.0                0.0            1.0   \n","42382           1.0     0.0      1.0                0.0            1.0   \n","11612           1.0     1.0      1.0                0.0            1.0   \n","17935           1.0     0.0      0.0                0.0            1.0   \n","2651            1.0     1.0      1.0                0.0            1.0   \n","\n","       GenHlth  MentHlth  PhysHlth  DiffWalk  Sex       Age  Education  \\\n","8658      0.25  0.000000       0.0       0.0  1.0  0.416667        0.8   \n","42382     0.75  1.000000       0.0       0.0  1.0  0.500000        0.4   \n","11612     0.00  0.333333       0.0       0.0  1.0  0.000000        0.8   \n","17935     0.25  0.000000       0.0       0.0  0.0  0.250000        0.8   \n","2651      0.00  0.000000       0.0       0.0  1.0  0.333333        1.0   \n","\n","         Income  Diabetes  \n","8658   0.714286       0.0  \n","42382  0.428571       0.0  \n","11612  1.000000       0.0  \n","17935  0.571429       0.0  \n","2651   1.000000       0.0  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Encode kolom dengan label encoding (telah dilakukan sebelumnya)\n","\n","df[\"Sex\"].replace({\"M\":1,\"F\":0}, inplace=True)\n","df[\"Diabetes\"].replace({True:1,False:0}, inplace=True)\n","df.sample(5)"]},{"cell_type":"code","execution_count":15,"metadata":{"cell_id":"8e32827ec5ac42eba4e6ad083f8d7cd5","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":352,"execution_start":1714040541698,"source_hash":"fcdc0358"},"outputs":[{"name":"stdout","output_type":"stream","text":["==================================================\n","Train set size: 37803\n","Validation set size: 4725\n","Test set size: 4726\n","==================================================\n"]}],"source":["# Bagi menjadi data train, validation dan test\n","X = df.drop(columns=\"Diabetes\")\n","y = df[\"Diabetes\"].copy()\n","\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=2024)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=2024)\n","\n","print(f\"{50*'='}\")\n","print(\"Train set size:\", X_train.shape[0])\n","print(\"Validation set size:\", X_val.shape[0])\n","print(\"Test set size:\", X_test.shape[0])\n","print(f\"{50*'='}\")"]},{"cell_type":"markdown","metadata":{"cell_id":"8e8f944226ae4435ad84a67c3d78165a","deepnote_cell_type":"markdown"},"source":["#### Data Sampling"]},{"cell_type":"code","execution_count":16,"metadata":{"cell_id":"9e22d757cc604482b4a75d21ce14fb44","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":782,"execution_start":1714043332188,"source_hash":"8a001e5a"},"outputs":[{"name":"stdout","output_type":"stream","text":["==================================================\n","Number sample: 10398\n","Accuracy: 0.7160389335590351\n","F1 Score: 0.4269854824935952\n","Confusion Matrix:\n","[[2884  154]\n"," [1188  500]]\n","==================================================\n"]}],"source":["# Undersampling\n","underSampler = RandomUnderSampler(sampling_strategy=\"majority\", random_state=2024)\n","underSampler_X_train, underSampler_y_train = underSampler.fit_resample(X_train, y_train)\n","\n","print(f\"{50*'='}\")\n","\n","print(f\"Number sample: {len(underSampler_X_train)}\")\n","\n","underSamplerLogistic = LogisticRegression(max_iter=1000, random_state=2024)\n","underSamplerLogistic.fit(underSampler_X_train, underSampler_y_train)\n","underSampler_y_pred = underSamplerLogistic.predict(X_test)\n","\n","print(f\"Accuracy: {accuracy_score(underSampler_y_pred, y_test)}\")\n","print(f\"F1 Score: {f1_score(underSampler_y_pred, y_test)}\")\n","print(f\"Confusion Matrix:\\n{confusion_matrix(underSampler_y_pred, y_test)}\")\n","\n","print(f\"{50*'='}\")"]},{"cell_type":"code","execution_count":17,"metadata":{"cell_id":"749a37ef289d409bb1bc7d8389c02bbb","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2551,"execution_start":1714043348408,"source_hash":"19ad728c"},"outputs":[{"name":"stdout","output_type":"stream","text":["==================================================\n","Number sample: 65208\n","Accuracy: 0.7147693609818028\n","F1 Score: 0.42442356959863364\n","Confusion Matrix:\n","[[2881  157]\n"," [1191  497]]\n","==================================================\n"]}],"source":["# Oversampling\n","overSampler = RandomOverSampler(sampling_strategy=\"minority\", random_state=2024)\n","overSampler_X_train, overSampler_y_train = overSampler.fit_resample(X_train, y_train)\n","\n","print(f\"{50*'='}\")\n","\n","print(f\"Number sample: {len(overSampler_X_train)}\")\n","\n","overSamplerLogistic = LogisticRegression(max_iter=1000, random_state=2024)\n","overSamplerLogistic.fit(overSampler_X_train, overSampler_y_train)\n","overSampler_y_pred = overSamplerLogistic.predict(X_test)\n","\n","print(f\"Accuracy: {accuracy_score(overSampler_y_pred, y_test)}\")\n","print(f\"F1 Score: {f1_score(overSampler_y_pred, y_test)}\")\n","print(f\"Confusion Matrix:\\n{confusion_matrix(overSampler_y_pred, y_test)}\")\n","\n","print(f\"{50*'='}\")"]},{"cell_type":"code","execution_count":18,"metadata":{"cell_id":"d455759caa584c59ad184c6560910fe8","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":3066,"execution_start":1714041456205,"source_hash":"962fe1a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["==================================================\n","Number sample: 65208\n","Accuracy: 0.7173085061362675\n","F1 Score: 0.42114384748700173\n","Confusion Matrix:\n","[[2904  168]\n"," [1168  486]]\n","==================================================\n"]}],"source":["# SMOTE\n","smoteSampler = SMOTE(random_state=2024)\n","smoteSampler_X_train, smoteSampler_y_train = smoteSampler.fit_resample(X_train, y_train)\n","\n","print(f\"{50*'='}\")\n","\n","print(f\"Number sample: {len(smoteSampler_X_train)}\")\n","\n","smoteSamplerLogistic = LogisticRegression(max_iter=1000, random_state=2024)\n","smoteSamplerLogistic.fit(smoteSampler_X_train, smoteSampler_y_train)\n","smoteSampler_y_pred = smoteSamplerLogistic.predict(X_test)\n","\n","print(f\"Accuracy: {accuracy_score(smoteSampler_y_pred, y_test)}\")\n","print(f\"F1 Score: {f1_score(smoteSampler_y_pred, y_test)}\")\n","print(f\"Confusion Matrix:\\n{confusion_matrix(smoteSampler_y_pred, y_test)}\")\n","\n","print(f\"{50*'='}\")"]},{"cell_type":"markdown","metadata":{"cell_id":"0d3f27be0669445795621069fdd10202","deepnote_cell_type":"markdown"},"source":["### Model"]},{"cell_type":"markdown","metadata":{"cell_id":"e7938cb0a93a4e62bf5a4ef93b1fb36b","deepnote_cell_type":"markdown"},"source":["#### Grid Search : Penentuan hyperparameter terbaik\n","\n"]},{"cell_type":"code","execution_count":19,"metadata":{"cell_id":"759d4fc1559b4ff9a4c7723c54bfb2d3","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":27528,"execution_start":1714044468833,"source_hash":"6225fdd2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 6 candidates, totalling 30 fits\n","Parameter: {'criterion': 'entropy', 'max_depth': 15}\n","Accuracy: 0.8015234870926788\n","F1 Score: 0.34951456310679613\n","Confusion Matrix:\n","[[3536  402]\n"," [ 536  252]]\n"]}],"source":["# Decision Tree Learning\n","\n","param_grid = {\n","    'max_depth': [5, 10, 15],\n","    'criterion': ['gini', 'entropy'],\n","}\n","\n","dtl = DecisionTreeClassifier(random_state=2024, splitter='best')\n","gridSearch_dtl = GridSearchCV(estimator=dtl, param_grid=param_grid, n_jobs=-1, verbose=2)\n","gridSearch_dtl.fit(smoteSampler_X_train, smoteSampler_y_train)\n","gridSearch_y_pred = gridSearch_dtl.predict(X_test)\n","\n","print(f\"Parameter: {gridSearch_dtl.best_params_}\") \n","print(f\"Accuracy: {accuracy_score(gridSearch_y_pred, y_test)}\")\n","print(f\"F1 Score: {f1_score(gridSearch_y_pred, y_test)}\")\n","print(f\"Confusion Matrix:\\n{confusion_matrix(gridSearch_y_pred, y_test)}\")"]},{"cell_type":"code","execution_count":20,"metadata":{"cell_id":"146d50116f0d44dc8313dcf0a119fec3","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":56806,"execution_start":1714044496363,"source_hash":"8e1727da"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 100 candidates, totalling 500 fits\n","Parameter: {'var_smoothing': 1.2328467394420658e-05}\n","Accuracy: 0.7156157426999576\n","F1 Score: 0.40372670807453415\n","Confusion Matrix:\n"," [[2927  199]\n"," [1145  455]]\n"]}],"source":["# Naive Bayes\n","\n","param_grid = {\n","    'var_smoothing': np.logspace(0,-9, num=100)\n","}\n","\n","nb = GaussianNB()\n","gridSearch_nb = GridSearchCV(estimator=nb, param_grid=param_grid, n_jobs=-1, verbose=2)\n","gridSearch_nb.fit(smoteSampler_X_train, smoteSampler_y_train)\n","gridSearch_y_pred_nb = gridSearch_nb.predict(X_test)\n","\n","print(\"Parameter:\", gridSearch_nb.best_params_)\n","print(\"Accuracy:\", accuracy_score(gridSearch_y_pred_nb, y_test))\n","print(\"F1 Score:\", f1_score(gridSearch_y_pred_nb, y_test))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(gridSearch_y_pred_nb, y_test))"]},{"cell_type":"code","execution_count":21,"metadata":{"cell_id":"bbd8fdd9d28e47a186a322d08b3df699","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":49214,"execution_start":1714046300950,"source_hash":"ab8be6f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 5 candidates, totalling 25 fits\n","Parameter: {'solver': 'lbfgs'}\n","Accuracy: 0.7173085061362675\n","F1 Score: 0.42114384748700173\n","Confusion Matrix:\n","[[2904  168]\n"," [1168  486]]\n"]}],"source":["# Logistic Regression\n","\n","param_grid = {\n","    \"solver\": [\"liblinear\", \"lbfgs\", \"newton-cg\", \"sag\", \"saga\"]\n","}\n","\n","lr = LogisticRegression(max_iter=1000, random_state=2024)\n","gridSearch_lr = GridSearchCV(estimator=lr, param_grid=param_grid, n_jobs=-1, verbose=2)\n","gridSearch_lr.fit(smoteSampler_X_train, smoteSampler_y_train)\n","gridSearch_y_pred = gridSearch_lr.predict(X_test)\n","\n","print(f\"Parameter: {gridSearch_lr.best_params_}\")\n","print(f\"Accuracy: {accuracy_score(gridSearch_y_pred, y_test)}\")\n","print(f\"F1 Score: {f1_score(gridSearch_y_pred, y_test)}\")\n","print(f\"Confusion Matrix:\\n{confusion_matrix(gridSearch_y_pred, y_test)}\")"]},{"cell_type":"code","execution_count":28,"metadata":{"cell_id":"9e157dbe900b488e8d13b6a616b4e85f","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":0,"execution_start":1714046364456,"source_hash":"8e0a568e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 50 candidates, totalling 250 fits\n","Parameter: {'criterion': 'gini', 'max_depth': 40, 'n_estimators': 50}\n","Accuracy: 0.841726618705036\n","F1 Score: 0.3175182481751825\n","Confusion Matrix:\n","[[3804  480]\n"," [ 268  174]]\n"]}],"source":["# Random Forest\n","\n","param_grid = {\n","    'n_estimators': [10, 20, 30, 40, 50],\n","    'max_depth': [25, 40, 70, 90, 100],\n","    'criterion': ['gini', 'entropy'],\n","}\n","\n","rf = RandomForestClassifier(random_state=2024)\n","gridSearch_rf = GridSearchCV(estimator=rf, param_grid=param_grid, n_jobs=-1, verbose=2)\n","gridSearch_rf.fit(smoteSampler_X_train, smoteSampler_y_train)\n","gridSearch_y_pred = gridSearch_rf.predict(X_test)\n","\n","print(f\"Parameter: {gridSearch_rf.best_params_}\")\n","print(f\"Accuracy: {accuracy_score(gridSearch_y_pred, y_test)}\")\n","print(f\"F1 Score: {f1_score(gridSearch_y_pred, y_test)}\")\n","print(f\"Confusion Matrix:\\n{confusion_matrix(gridSearch_y_pred, y_test)}\")"]},{"cell_type":"code","execution_count":23,"metadata":{"cell_id":"3acd359fe47d4b21a641a3c51bd61908","deepnote_cell_type":"code"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 3 candidates, totalling 15 fits\n","Parameter: {'kernel': 'rbf'}\n","Accuracy: 0.7179432924248836\n","F1 Score: 0.41147902869757175\n","Confusion Matrix:\n"," [[2927  188]\n"," [1145  466]]\n"]}],"source":["# Support Vector Machine\n","\n","param_grid = {\n","    'kernel': ['rbf', 'linear', 'poly']\n","}\n","\n","svm = SVC(random_state = 2024)\n","gridSearch_svm = GridSearchCV(estimator=svm, param_grid=param_grid, n_jobs=-1, verbose=2)\n","gridSearch_svm.fit(smoteSampler_X_train, smoteSampler_y_train)\n","gridSearch_y_pred_svm = gridSearch_svm.predict(X_test)\n","\n","print(\"Parameter:\", gridSearch_svm.best_params_)\n","print(\"Accuracy:\", accuracy_score(gridSearch_y_pred_svm, y_test))\n","print(\"F1 Score:\", f1_score(gridSearch_y_pred_svm, y_test))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(gridSearch_y_pred_svm, y_test))"]},{"cell_type":"code","execution_count":24,"metadata":{"cell_id":"baf80cdd12474e84b9044ae6bfb24b4e","deepnote_cell_type":"code"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"]},{"name":"stdout","output_type":"stream","text":["Parameter: {'n_neighbors': 1}\n","Accuracy: 0.770207363520948\n","F1 Score: 0.3047375160051216\n","Confusion Matrix:\n"," [[3402  416]\n"," [ 670  238]]\n"]}],"source":["# K Nearest Neighbor\n","\n","k_range = list(range(1, 31))\n","param_grid = dict(n_neighbors=k_range)\n","\n","knn = KNeighborsClassifier()\n","gridSearch_knn = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy', return_train_score=False,verbose=1)\n","gridSearch_knn.fit(smoteSampler_X_train, smoteSampler_y_train)\n","gridSearch_y_pred_knn = gridSearch_knn.predict(X_test)\n","\n","print(\"Parameter:\", gridSearch_knn.best_params_)\n","print(\"Accuracy:\", accuracy_score(gridSearch_y_pred_knn, y_test))\n","print(\"F1 Score:\", f1_score(gridSearch_y_pred_knn, y_test))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(gridSearch_y_pred_knn, y_test))"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"]},{"ename":"ValueError","evalue":"\nAll the 180 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n180 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 925, in _fit\n    X, y = self._initialize(X, y)\n  File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 862, in _initialize\n    self.model_ = self._build_keras_model()\n  File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 433, in _build_keras_model\n    model = final_build_fn(**build_params)\nTypeError: buildModel() missing 1 required positional argument: 'optimizer'\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[29], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m nn \u001b[38;5;241m=\u001b[39m KerasRegressor(build_fn\u001b[38;5;241m=\u001b[39mbuildModel, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     19\u001b[0m gridSearch_nn \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mnn, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mgridSearch_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmoteSampler_X_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmoteSampler_y_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m gridSearch_y_pred_nn \u001b[38;5;241m=\u001b[39m gridSearch_nn\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter:\u001b[39m\u001b[38;5;124m\"\u001b[39m, gridSearch_nn\u001b[38;5;241m.\u001b[39mbest_params_)\n","File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:947\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    943\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    945\u001b[0m     )\n\u001b[1;32m--> 947\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n","File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    530\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    531\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m     )\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    539\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    546\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: \nAll the 180 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n180 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 925, in _fit\n    X, y = self._initialize(X, y)\n  File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 862, in _initialize\n    self.model_ = self._build_keras_model()\n  File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 433, in _build_keras_model\n    model = final_build_fn(**build_params)\nTypeError: buildModel() missing 1 required positional argument: 'optimizer'\n"]}],"source":["# Neural Networks\n","\n","def buildModel(optimizer):\n","    classifier = Sequential()\n","    classifier.add(Dense(units = 128, activation = 'relu'))\n","    classifier.add(Dense(units = 64, activation = 'relu'))\n","    classifier.add(Dense(units = 32, activation = 'relu'))\n","    classifier.add(Dense(units = 1, activation = 'linear'))\n","    classifier.compile(loss='mean_absolute_error', optimizer=optimizer, metrics=['mean_absolute_error'])\n","    return classifier\n","\n","param_grid = {\n","    'batch_size': [10, 20, 40, 60, 80, 100],\n","    'epochs': [10, 50, 100],\n","    'optimizer': ['adam', 'rmsprop']\n","}\n","\n","nn = KerasRegressor(build_fn=buildModel, verbose=0)\n","gridSearch_nn = GridSearchCV(estimator=nn, param_grid=param_grid, n_jobs=-1, verbose=2)\n","gridSearch_nn.fit(smoteSampler_X_train, smoteSampler_y_train)\n","gridSearch_y_pred_nn = gridSearch_nn.predict(X_test)\n","\n","print(\"Parameter:\", gridSearch_nn.best_params_)\n","print(\"Accuracy:\", accuracy_score(gridSearch_y_pred_nn, y_test))\n","print(\"F1 Score:\", f1_score(gridSearch_y_pred_nn, y_test))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(gridSearch_y_pred_nn, y_test))"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Training"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.8391534391534392\n","F1 Score: 0.3770491803278688\n","Confusion Matrix:\n","[[3735  449]\n"," [ 311  230]]\n"]}],"source":["rf_1 = RandomForestClassifier(criterion=\"gini\", max_depth=25, n_estimators=40, random_state=2024)\n","rf_2 = RandomForestClassifier(criterion=\"gini\", max_depth=25, n_estimators=40, random_state=2025)\n","rf_3 = RandomForestClassifier(criterion=\"gini\", max_depth=25, n_estimators=40, random_state=2026)\n","final_estimator = LogisticRegression(solver=\"liblinear\", max_iter=1000, random_state=2024)\n","\n","stacking_ensemble = StackingClassifier(\n","    estimators=[\n","        (\"rf_1\",rf_1),\n","        (\"rf_2\", rf_2),\n","        (\"rf_3\", rf_3),\n","    ],\n","    final_estimator=final_estimator\n",")\n","stacking_ensemble.fit(smoteSampler_X_train, smoteSampler_y_train)\n","stacking_ensemble_pred = stacking_ensemble.predict(X_val)\n","\n","print(f\"Accuracy: {accuracy_score(stacking_ensemble_pred, y_val)}\")\n","print(f\"F1 Score: {f1_score(stacking_ensemble_pred, y_val)}\")\n","print(f\"Confusion Matrix:\\n{confusion_matrix(stacking_ensemble_pred, y_val)}\")"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=c384c4b3-0606-4ac0-935c-3feaec40b0ba' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Testing"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["==================================================\n","Accuracy: 0.8322048243757935\n","F1 Score: 0.3364016736401674\n","Confusion Matrix:\n","[[3732  453]\n"," [ 340  201]]\n","==================================================\n"]}],"source":["print(f\"{50*'='}\")\n","stacking_ensemble_test = stacking_ensemble.predict(X_test)\n","\n","print(f\"Accuracy: {accuracy_score(stacking_ensemble_test, y_test)}\")\n","print(f\"F1 Score: {f1_score(stacking_ensemble_test, y_test)}\")\n","print(f\"Confusion Matrix:\\n{confusion_matrix(stacking_ensemble_test, y_test)}\")\n","print(f\"{50*'='}\")"]}],"metadata":{"deepnote_execution_queue":[],"deepnote_notebook_id":"ede5219629d84018bd27ab94072dcb19","deepnote_persisted_session":{"createdAt":"2024-04-25T10:01:09.301Z"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
